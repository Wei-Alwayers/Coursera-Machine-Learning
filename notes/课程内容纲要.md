# Machine Learning

> 课程概述：第一部分为supervised learning，包括regression和classfication，第二部分是advanced leaning算法，主要是neural network和decision tree，第三部分是unsupervised learning，recommendation system和reinforcement learning

## 1. Supervised Learning

### Linear Regression

1. 什么是Linear Regression: x, y, m
2. 如何评价model好坏：cost function -- squared error cost function
3. 怎么降低cost function：gradient descent
4. multiple linear regression: vectorization, numpy
5. 不同feature的范围不同：scaling(Z-score normalization)
6. learning curve, converged
7. learning curve上升的可能原因：learning rate(α)
8. polynomial regression

### Classfication

1. logistic regression model: sigmoid function, threshold, boundary line
2. logistic loss function: cost function, gradient descent
3. overfitting和underfitting：high varience, high bias
4. 如何解决overfitting：regularization, lambda

## 2 Advanced Learning Algorithm

### Neural Network

1. neural network: input layer, hidden layer, output layer, activation function
2. vectorization: vector matrix multiplication
3. 使用Tensorflow训练neural network
4. 选择activation function: sigmoid, linear, ReLU(output layer和hidden layer都选择什么)
5. multiclass classfication problem: 不能用logistic，而使用softmax
6. multi-lable classfication problem
7. 其他optimization算法：Adam(自动调整α都gradient descent)
8. 其他layer类型：除了dense，还有convolutional layer(只关注上一layer的部分output)
9. 计算机如何计算derivate：backpropagation
10. 怎么评价model好坏：training set, test set, cross validation set
11. 根据$J_{test}$和$J_{CV}$来判断model有无overfit和underfit问题：baseline level
12. lambda（regularization）对model的影响
13. training set大小对model的影响
14. 怎么构建ML系统
15. 怎么增加数据：data augmentation, data synothesis
16. transfer learning
17. 怎么解决skewed data问题：precision和recall，F1-score(Harmonic Mean)

## Decision Tree

1. decision tree构建过程：purity, split, entropy  
2. 怎么选split feature: reduction of entropy, information gain
3. 如果feature有多个可能值：one-hot encoding
4. 如果一个feature取值无穷：threshold
5. 怎么用decision tree解决regression problem：entropy -> varience
6. decision tree的weakness之一是small change大影响：tree ensemble, sampling with replacement, XGBootsing
7. decision tree V.S neural network

## 3. Unsupervised Learning

### Clustering

1. 什么是clustering
2. K-means algorithm: cluster centroid
3. 怎么选cluster个数

### Anomaly Detection

1. Gaussian(normal/bell-shaped) distribution : μ, ε
2. 有多个feature：Density Estamation
3. 判断算法好坏：real-number evaluation
4. 有labeled数据为什么不用supervised learning
5. 怎么选feature：对feature进行变形，组合新的feature

### Recommendation System

1. collaborative filtering: mean normalization, 还可用于找related items
2. content-based filtering: 两种算法的不同，deep learning
3. 如果数据规模很大：retrieval 和 ranking
4. 多个feature进行可视化的方法：principal component analysis

### Reinforcement Learning

1. 算法原理：discount factor, policy, Markov Decision Process(MDP)
2. Q-function(state-action value function): Bellman Equation, stochastic environment
3. 如果是continues state space
4. 改善model方法：改结构、ε-greedy policy, mini-batches, soft updates

